{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e04308",
   "metadata": {},
   "source": [
    "## ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3491726",
   "metadata": {},
   "source": [
    "The ColumnTransformer is a very powerful tool in scikit-learn that allows you to apply different preprocessing steps to different subsets of features (columns) in a dataset. This is particularly useful when dealing with datasets that contain both numerical and categorical data. Each type of data might require a different type of preprocessing or transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620179cb",
   "metadata": {},
   "source": [
    "**Why Use ColumnTransformer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6190de",
   "metadata": {},
   "source": [
    "* **Streamlining the Preprocessing:** Instead of manually applying transformations on subsets of data, the ColumnTransformer allows you to apply different transformations to different columns in a single step.\n",
    "* **Integration in Pipelines:** ColumnTransformer can be easily used in a pipeline, allowing you to apply the same set of transformations every time you train a model, ensuring that no data leakage or mistakes happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e568798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1ed4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Age': [25, 30, np.nan, 40, 45],  # Missing value in Age\n",
    "    'Salary': [50000, 60000, 70000, np.nan, 90000],  # Missing value in Salary\n",
    "    'Owner': ['First Owner', 'Second Owner', 'Third Owner', 'First Owner', 'Second Owner'],\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d955c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Age', 'Salary', 'Owner', 'Gender', 'City']]\n",
    "y = [0, 1, 0, 1, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a997831",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90cc6a3",
   "metadata": {},
   "source": [
    "**--- Individual Transformation Steps ---**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527476d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SimpleImputer to handle missing values in 'Age' and 'Salary'\n",
    "\n",
    "simple_imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = simple_imputer.fit_transform(X_train[['Age', 'Salary']])\n",
    "X_test_imputed = simple_imputer.transform(X_test[['Age', 'Salary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f58196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply OrdinalEncoder to 'Owner' (ordinal feature)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X_train_ord = ordinal_encoder.fit_transform(X_train[['Owner']])\n",
    "X_test_ord = ordinal_encoder.transform(X_test[['Owner']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcc6b8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Apply OneHotEncoder to 'Gender' and 'City' (categorical features)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "X_train_cat = one_hot_encoder.fit_transform(X_train[['Gender', 'City']])\n",
    "X_test_cat = one_hot_encoder.transform(X_test[['Gender', 'City']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d73a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all transformed columns (for comparison)\n",
    "\n",
    "X_train_combined = np.hstack([X_train_imputed, X_train_ord, X_train_cat])\n",
    "X_test_combined = np.hstack([X_test_imputed, X_test_ord, X_test_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7696a113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed X_train (individual transformations):\n",
      "[[4.50000000e+01 9.00000000e+04 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " [3.66666667e+01 7.00000000e+04 2.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [2.50000000e+01 5.00000000e+04 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [4.00000000e+01 7.00000000e+04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed X_train (individual transformations):\")\n",
    "print(X_train_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d5b9def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16591046",
   "metadata": {},
   "source": [
    "**--- Combined Transformation Steps Using ColumnTransformer ---**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c92630f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ColumnTransformer\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), ['Age', 'Salary']),  # Impute missing values for numerical columns\n",
    "        ('ord', OrdinalEncoder(), ['Owner']),  # Apply OrdinalEncoder to 'Owner' column\n",
    "        ('cat', OneHotEncoder(drop='first', sparse=False), ['Gender', 'City'])  # Apply OneHotEncoder to 'Gender' and 'City'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ded636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Apply ColumnTransformer on the training and test sets\n",
    "\n",
    "X_train_transformed = column_transformer.fit_transform(X_train)\n",
    "X_test_transformed = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b3b9bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed X_train (using ColumnTransformer):\n",
      "[[4.50000000e+01 9.00000000e+04 1.00000000e+00 1.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " [3.66666667e+01 7.00000000e+04 2.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [2.50000000e+01 5.00000000e+04 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [4.00000000e+01 7.00000000e+04 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTransformed X_train (using ColumnTransformer):\")\n",
    "print(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d336f31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Are the results the same?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Compare the results from the individual and ColumnTransformer methods\n",
    "print(\"\\nAre the results the same?\")\n",
    "print(np.array_equal(X_train_combined, X_train_transformed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
